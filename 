warning: LF will be replaced by CRLF in base_game_model.py.
The file will have its original line endings in your working directory
warning: LF will be replaced by CRLF in ddqn_game_model.py.
The file will have its original line endings in your working directory
warning: LF will be replaced by CRLF in env_krakout.py.
The file will have its original line endings in your working directory
warning: LF will be replaced by CRLF in env_renegade.py.
The file will have its original line endings in your working directory
warning: LF will be replaced by CRLF in frame.py.
The file will have its original line endings in your working directory
warning: LF will be replaced by CRLF in gym_wrappers.py.
The file will have its original line endings in your working directory
warning: LF will be replaced by CRLF in main.py.
The file will have its original line endings in your working directory
[1mdiff --git a/base_game_model.py b/base_game_model.py[m
[1mindex 8fd1278..44f8f75 100644[m
[1m--- a/base_game_model.py[m
[1m+++ b/base_game_model.py[m
[36m@@ -13,6 +13,9 @@[m [mclass BaseGameModel:[m
         self.logger.add_step(step)[m
         self.logger.add_run(run)[m
 [m
[32m+[m[32m    def save(self, run, total_step):[m
[32m+[m[32m        pass[m
[32m+[m
     def get_move(self, state):[m
         pass[m
 [m
[1mdiff --git a/ddqn_game_model.py b/ddqn_game_model.py[m
[1mindex 1d66b68..b9b0397 100644[m
[1m--- a/ddqn_game_model.py[m
[1m+++ b/ddqn_game_model.py[m
[36m@@ -2,9 +2,12 @@[m [mimport numpy as np[m
 import os[m
 import random[m
 import shutil[m
[32m+[m[32mimport gzip[m
[32m+[m[32mimport struct[m
 from statistics import mean[m
 from base_game_model import BaseGameModel[m
 from convolutional_neural_network import ConvolutionalNeuralNetwork[m
[32m+[m[32mfrom frame import Frame[m
 [m
 GAMMA = 0.99[m
 MEMORY_SIZE = 900000[m
[36m@@ -12,7 +15,7 @@[m [mBATCH_SIZE = 32[m
 TRAINING_FREQUENCY = 4[m
 TARGET_NETWORK_UPDATE_FREQUENCY = 40000[m
 MODEL_PERSISTENCE_UPDATE_FREQUENCY = 10000[m
[31m-REPLAY_START_SIZE = 50000[m
[32m+[m[32mREPLAY_START_SIZE = 500[m
 [m
 EXPLORATION_MAX = 1.0[m
 EXPLORATION_MIN = 0.1[m
[36m@@ -20,19 +23,22 @@[m [mEXPLORATION_TEST = 0.02[m
 EXPLORATION_STEPS = 850000[m
 EXPLORATION_DECAY = (EXPLORATION_MAX-EXPLORATION_MIN)/EXPLORATION_STEPS[m
 [m
[31m-[m
 class DDQNGameModel(BaseGameModel):[m
 [m
[31m-    def __init__(self, game_name, mode_name, input_shape, action_space, logger_path, model_path):[m
[32m+[m[32m    def __init__(self, game_name, mode_name, input_shape, action_space, logger_path, model_path, train_data_path=None):[m
         BaseGameModel.__init__(self, game_name,[m
                                mode_name,[m
                                logger_path,[m
                                input_shape,[m
                                action_space)[m
[32m+[m
         self.model_path = model_path[m
[32m+[m[32m        self.train_data_path = train_data_path[m
         self.ddqn = ConvolutionalNeuralNetwork(self.input_shape, action_space).model[m
         if os.path.isfile(self.model_path):[m
             self.ddqn.load_weights(self.model_path)[m
[32m+[m[32m        if not os.path.exists(os.path.dirname(self.model_path)):[m
[32m+[m[32m            os.makedirs(os.path.dirname(self.model_path))[m
 [m
     def _save_model(self):[m
         self.ddqn.save_weights(self.model_path)[m
[36m@@ -41,14 +47,15 @@[m [mclass DDQNGameModel(BaseGameModel):[m
 class DDQNSolver(DDQNGameModel):[m
 [m
     def __init__(self, game_name, input_shape, action_space):[m
[31m-        testing_model_path = "./output/neural_nets/" + game_name + "/ddqn/testing/model.h5"[m
[32m+[m[32m        logging_path       = "./output/" + game_name + "/testing/log/" + self._get_date() + "/"[m
[32m+[m[32m        testing_model_path = "./output/" + game_name + "/testing/model.h5"[m
         assert os.path.exists(os.path.dirname(testing_model_path)), "No testing model in: " + str(testing_model_path)[m
         DDQNGameModel.__init__(self,[m
                                game_name,[m
                                "DDQN testing",[m
                                input_shape,[m
                                action_space,[m
[31m-                               "./output/logs/" + game_name + "/ddqn/testing/" + self._get_date() + "/",[m
[32m+[m[32m                               logging_path,[m
                                testing_model_path)[m
 [m
     def move(self, state):[m
[36m@@ -66,17 +73,95 @@[m [mclass DDQNTrainer(DDQNGameModel):[m
                                "DDQN training",[m
                                input_shape,[m
                                action_space,[m
[31m-                               "./output/logs/" + game_name + "/ddqn/training/" + self._get_date() + "/",[m
[31m-                               "./output/neural_nets/" + game_name + "/ddqn/" + self._get_date() + "/model.h5")[m
[31m-[m
[31m-        if os.path.exists(os.path.dirname(self.model_path)):[m
[31m-            shutil.rmtree(os.path.dirname(self.model_path), ignore_errors=True)[m
[31m-        os.makedirs(os.path.dirname(self.model_path))[m
[32m+[m[32m                               "./output/" + game_name + "/training/log/" + self._get_date() + "/",[m
[32m+[m[32m                               "./output/" + game_name + "/training/model.h5",[m
[32m+[m[32m                               "./output/" + game_name + "/training/training_data.gz")[m
 [m
         self.ddqn_target = ConvolutionalNeuralNetwork(self.input_shape, action_space).model[m
         self._reset_target_network()[m
[32m+[m[32m        self._load_training_data()[m
[32m+[m
[32m+[m[32m    def _load_training_data(self):[m
         self.epsilon = EXPLORATION_MAX[m
         self.memory = [][m
[32m+[m[32m        self.initial_run = 0[m
[32m+[m[32m        self.initial_total_step = 0[m
[32m+[m[32m        self.struct_header = struct.Struct('IIIIIf')[m
[32m+[m[32m        self.struct_record = struct.Struct('IIIBB')[m
[32m+[m[32m        if not os.path.isfile(self.train_data_path):[m
[32m+[m[32m            return[m
[32m+[m[32m        print('found training data in %s, loading' % (self.train_data_path,))[m
[32m+[m[32m        with gzip.open(self.train_data_path, 'rb') as f:[m
[32m+[m[32m            hdr = f.read(self.struct_header.size)[m
[32m+[m[32m            frame_count, mem_count, img_size, ir, its, eps = self.struct_header.unpack_from(hdr)[m
[32m+[m[32m            self.initial_run = ir[m
[32m+[m[32m            self.initial_total_step = its[m
[32m+[m[32m            self.epsilon = eps[m
[32m+[m
[32m+[m[32m            # load frames into simple list[m
[32m+[m[32m            all_frames = [][m
[32m+[m[32m            for i in range(frame_count):[m
[32m+[m[32m                if i % 1000 == 0:[m
[32m+[m[32m                    print('loaded %d frames out of %d' % (i, frame_count))[m
[32m+[m[32m                data = bytearray(f.read(img_size))[m
[32m+[m[32m                all_frames.append(Frame([data]))[m
[32m+[m[32m            print('loaded %d frames' % (frame_count,))[m
[32m+[m
[32m+[m[32m            # load records into memory, reference frames in list by index[m
[32m+[m[32m            recsz = self.struct_record.size[m
[32m+[m[32m            for i in range(mem_count):[m
[32m+[m[32m                if i % 1000 == 0:[m
[32m+[m[32m                    print('loaded %d records out of %d' % (i, mem_count))[m
[32m+[m[32m                ics,ins,rw,ac,t = self.struct_record.unpack_from(f.read(recsz))[m
[32m+[m[32m                cs = all_frames[ics][m
[32m+[m[32m                ns = all_frames[ins][m
[32m+[m[32m                self.remember(cs,ac,rw,ns,True if t == 1 else False)[m
[32m+[m[32m            print('loaded %d records' % (mem_count,))[m
[32m+[m[32m            all_frames = None[m
[32m+[m
[32m+[m[32m    def save(self, run, total_step):[m
[32m+[m[32m        if not os.path.exists(os.path.dirname(self.train_data_path)):[m
[32m+[m[32m            os.makedirs(os.path.dirname(self.train_data_path))[m
[32m+[m[32m        if os.path.isfile(self.train_data_path):[m
[32m+[m[32m            if os.path.isfile(self.train_data_path + ".bak"):[m
[32m+[m[32m                os.remove(self.train_data_path + ".bak")[m
[32m+[m[32m            os.rename(self.train_data_path, self.train_data_path + ".bak")[m
[32m+[m
[32m+[m[32m        img_size = len(self.memory[0]['current_state'].as_bytes())[m
[32m+[m[32m        with gzip.open(self.train_data_path, 'wb') as f:[m
[32m+[m[32m            all_frames = {}[m
[32m+[m[32m            mem_count = len(self.memory)[m
[32m+[m
[32m+[m[32m            # first count and index all unique frames[m
[32m+[m[32m            print('indexing frame data')[m
[32m+[m[32m            for r in self.memory:[m
[32m+[m[32m                cs = r['current_state'][m
[32m+[m[32m                ns = r['next_state'][m
[32m+[m[32m                if cs not in all_frames: all_frames[cs] = cs.index = len(all_frames)[m
[32m+[m[32m                if ns not in all_frames: all_frames[ns] = ns.index = len(all_frames)[m
[32m+[m
[32m+[m[32m            # save all frames first, ordered by index[m
[32m+[m[32m            print('frame data indexing complete, saving frames')[m
[32m+[m[32m            frame_count = len(all_frames)[m
[32m+[m[32m            f.write(self.struct_header.pack(frame_count,mem_count,img_size,run,total_step,self.epsilon))[m
[32m+[m[32m            processed_records = 0[m
[32m+[m[32m            for k in sorted(all_frames,key=lambda x: x.index):[m
[32m+[m[32m                if processed_records%1000==0:[m
[32m+[m[32m                    print('saved %d records out of %d' % (processed_records, frame_count))[m
[32m+[m[32m                f.write(k.as_bytes())[m[41m [m
[32m+[m[32m                processed_records = processed_records+1[m
[32m+[m
[32m+[m[32m            # now save all memory records with frame index instead of real frame[m
[32m+[m[32m            print('saved %d frames, now saving %d transitions' % (frame_count, mem_count))[m
[32m+[m[32m            for i in range(mem_count):[m[41m [m
[32m+[m[32m                record = self.memory[i][m
[32m+[m[32m                cs = record['current_state'][m
[32m+[m[32m                ns = record['next_state'][m
[32m+[m[32m                ac = record['action'][m
[32m+[m[32m                rw = record['reward'][m
[32m+[m[32m                t = 1 if record['terminal'] else 0[m
[32m+[m[32m                f.write(self.struct_record.pack(cs.index,ns.index,rw,ac,t))[m
[32m+[m[32m            print('saved %d transitions' % (mem_count,))[m
 [m
     def move(self, state):[m
         if np.random.rand() < self.epsilon or len(self.memory) < REPLAY_START_SIZE:[m
[36m@@ -85,13 +170,15 @@[m [mclass DDQNTrainer(DDQNGameModel):[m
         return np.argmax(q_values[0])[m
 [m
     def remember(self, current_state, action, reward, next_state, terminal):[m
[31m-        self.memory.append({"current_state": current_state,[m
[31m-                            "action": action,[m
[31m-                            "reward": reward,[m
[31m-                            "next_state": next_state,[m
[31m-                            "terminal": terminal})[m
[32m+[m[32m        data = {"current_state": current_state,[m
[32m+[m[32m                "action": action,[m
[32m+[m[32m                "reward": reward,[m
[32m+[m[32m                "next_state": next_state,[m
[32m+[m[32m                "terminal": terminal}[m
[32m+[m[32m        self.memory.append(data)[m
         if len(self.memory) > MEMORY_SIZE:[m
             self.memory.pop(0)[m
[32m+[m[32m        #self.queue.put(data)[m
 [m
     def step_update(self, total_step):[m
         if len(self.memory) < REPLAY_START_SIZE:[m
[1mdiff --git a/env_krakout.py b/env_krakout.py[m
[1mindex e7ad898..5e35016 100644[m
[1m--- a/env_krakout.py[m
[1m+++ b/env_krakout.py[m
[36m@@ -80,4 +80,12 @@[m [mclass KrakoutEnv():[m
         return reward[m
 [m
     def ReadScore(self):[m
[31m-        return 10 * (self.emu.GetByte(0x5B71) + (self.emu.GetByte(0x5B72) * 256))[m
[32m+[m[32m        emu = self.emu[m
[32m+[m[32m        d1 = emu.GetByte(0xB676) - 0x30[m
[32m+[m[32m        d2 = emu.GetByte(0xB677) - 0x30[m
[32m+[m[32m        d3 = emu.GetByte(0xB678) - 0x30[m
[32m+[m[32m        d4 = emu.GetByte(0xB679) - 0x30[m
[32m+[m[32m        d5 = emu.GetByte(0xB67A) - 0x30[m
[32m+[m[32m        d6 = emu.GetByte(0xB67B) - 0x30[m
[32m+[m[32m        d7 = emu.GetByte(0xB67C) - 0x30[m
[32m+[m[32m        return d1 * 1000000 + d2 * 100000 + d3 * 10000 + d4 * 1000 + d5 * 100 + d6 * 10 + d7[m
[1mdiff --git a/env_renegade.py b/env_renegade.py[m
[1mindex 1c46c02..3934a37 100644[m
[1m--- a/env_renegade.py[m
[1m+++ b/env_renegade.py[m
[36m@@ -47,10 +47,12 @@[m [mclass RenegadeEnv():[m
         oldLives = self.lives;[m
         self.lives = newLives;[m
 [m
[31m-        if self.lives == 0: # terminal state[m
[31m-            return True;[m
[32m+[m[32m        if emu.GetByte(0xBF13) == 0x0F: # even more strict condition - consider knocked down as terminal[m
[32m+[m[32m            return True[m
[32m+[m[32m        if self.lives == 1: # consider loss of 1 life a terminal state[m
[32m+[m[32m            return True[m
 [m
[31m-        return False;[m
[32m+[m[32m        return False[m
 [m
     def UpdateReward(self):[m
         newScore = self.ReadScore()[m
[1mdiff --git a/frame.py b/frame.py[m
[1mindex 3be0ab7..3c9fbb1 100644[m
[1m--- a/frame.py[m
[1m+++ b/frame.py[m
[36m@@ -10,10 +10,20 @@[m [mclass Frame():[m
         self._frames = frames[m
 [m
     def __array__(self, dtype=None):[m
[31m-        out = np.concatenate(self._frames, axis=0).reshape(4,FRAME_SIZE,FRAME_SIZE)[m
[31m-        if dtype is not None:[m
[31m-            out = out.astype(dtype)[m
[31m-        return out[m
[32m+[m[32m        try:[m
[32m+[m[32m            out = np.concatenate(self._frames, axis=0).reshape(4,FRAME_SIZE,FRAME_SIZE)[m
[32m+[m[32m            if dtype is not None:[m
[32m+[m[32m                out = out.astype(dtype)[m
[32m+[m[32m            return out[m
[32m+[m[32m        except:[m
[32m+[m[32m            print(len(self._frames))[m
[32m+[m[32m            print(type(self._frames))[m
[32m+[m[32m            print(len(self._frames[0]))[m
[32m+[m[32m            print(type(self._frames[0]))[m
[32m+[m[32m            raise[m
[32m+[m
[32m+[m[32m    def as_bytes(self):[m
[32m+[m[32m        return b"".join(self._frames)[m
 [m
     @staticmethod[m
     def halve_image(image) :[m
[36m@@ -37,6 +47,7 @@[m [mclass Frame():[m
         img = Frame.halve_image(img)[m
         return bytearray(img.swapaxes(0,1)*32)[m
 [m
[32m+[m[32m    @staticmethod[m
     def Join(*argv):[m
         lst = [x for x in argv][m
         return Frame(lst)[m
[1mdiff --git a/gym_wrappers.py b/gym_wrappers.py[m
[1mindex e497cfa..08ef740 100644[m
[1m--- a/gym_wrappers.py[m
[1m+++ b/gym_wrappers.py[m
[36m@@ -28,7 +28,7 @@[m [mclass MainGymWrapper():[m
         return self.env.action_space[m
 [m
     def reset(self):[m
[31m-        return self.env.reset(np.random.randint(self.skip))[m
[32m+[m[32m        return self.env.reset(np.random.randint(self.skip) if self.skip > 0 else 0)[m
 [m
     def render(self):[m
         if self.viewer == None:[m
[1mdiff --git a/main.py b/main.py[m
[1mindex ae5f877..405ab39 100644[m
[1m--- a/main.py[m
[1m+++ b/main.py[m
[36m@@ -1,3 +1,4 @@[m
[32m+[m[32mimport keyboard[m
 import time[m
 import argparse[m
 import numpy as np[m
[36m@@ -10,17 +11,19 @@[m [mINPUT_SHAPE = (FRAMES_IN_OBSERVATION, FRAME_SIZE, FRAME_SIZE)[m
 [m
 [m
 class Main:[m
[31m-[m
[31m-    def __init__(self):[m
[32m+[m[32m    def run(self):[m
         game_name, game_mode, render, total_step_limit, total_run_limit, clip, skip = self._args()[m
         env = MainGymWrapper(game_name, skip)[m
         self._main_loop(self._game_model(game_mode, game_name, env.action_space), env, render, total_step_limit, total_run_limit, clip)[m
 [m
     def _main_loop(self, game_model, env, render, total_step_limit, total_run_limit, clip):[m
[31m-        run = 0[m
[31m-        total_step = 0[m
[32m+[m[32m        run = game_model.initial_run[m
[32m+[m[32m        total_step = game_model.initial_total_step[m
         viewer = None[m
 [m
[32m+[m[32m        if run != 0:[m
[32m+[m[32m            print ("Continue from run " + str(run))[m
[32m+[m
         while True:[m
             if total_run_limit is not None and run >= total_run_limit:[m
                 print ("Reached total run limit of: " + str(total_run_limit))[m
[36m@@ -31,6 +34,11 @@[m [mclass Main:[m
             step = 0[m
             score = 0[m
             while True:[m
[32m+[m[32m                if keyboard.is_pressed("q"):[m
[32m+[m[32m                    print ("Quit button pressed, saving state")[m
[32m+[m[32m                    game_model.save(run, total_step)[m
[32m+[m[32m                    exit(0)[m
[32m+[m
                 if total_step >= total_step_limit:[m
                     print ("Reached total step limit of: " + str(total_step_limit))[m
                     exit(0)[m
[36m@@ -48,7 +56,7 @@[m [mclass Main:[m
                 game_model.remember(current_state, action, reward, next_state, terminal)[m
                 current_state = next_state[m
                 game_model.step_update(total_step)[m
[31m-                time.sleep(1)[m
[32m+[m[32m                #time.sleep(0.1)[m
                 if terminal:[m
                     print('score:%d\tsteps:%d\ttotal:%d\trun:%d' % (score, step, total_step, run))[m
                     game_model.save_run(score, step, run)[m
[36m@@ -90,6 +98,6 @@[m [mclass Main:[m
             print ("Unrecognized mode. Use --help")[m
             exit(1)[m
 [m
[31m-[m
 if __name__ == "__main__":[m
[31m-    Main()[m
[32m+[m[32m    m = Main()[m
[32m+[m[32m    m.run()[m
